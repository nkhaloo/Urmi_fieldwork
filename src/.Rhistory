)
cv <- xgb.cv(
params = params,
data = dtrain,
nrounds = 50,
nfold = 5,
verbose = 0,
early_stopping_rounds = 10,
maximize = FALSE
)
best_error <- min(cv$evaluation_log$test_error_mean)
best_accuracy <- 1 - best_error
results_mfcc[[v]] <- list(
vowel = v,
n_tokens = nrow(df_subset),
best_error = best_error,
best_accuracy = best_accuracy
)
}
results_mfcc_df <- bind_rows(results_mfcc)
print("Results for MFCC-only model (using midpoint MFCCs):")
print(results_mfcc_df)
# Load required packages
library(tuneR)      # For audio file reading and processing
library(rPraat)     # For reading Praat TextGrid files
library(tidyverse)  # For data manipulation
library(xgboost)    # For modeling with XGBoost
library(caret)      # Optional, for additional modeling utilities
### PART 1: MFCC EXTRACTION & PROCESSING
data_dir <- "/Users/noahkhaloo/Desktop/Urmi_fieldwork/s1/vowels/vowels_arpabet"
wav_files <- list.files(path = data_dir, pattern = "\\.wav$", full.names = TRUE)
# Initialize empty list to store MFCC results
mfcc_results <- list()
# Loop through each audio file
for (wav_path in wav_files) {
# Get base name and corresponding TextGrid path
base_name <- tools::file_path_sans_ext(basename(wav_path))
tg_path <- file.path(data_dir, paste0(base_name, ".TextGrid"))
if (!file.exists(tg_path)) next
# Read audio file and TextGrid
wave_obj <- readWave(wav_path)
tg <- tg.read(tg_path)
# Assume the first tier is the vowels tier
vowels_tier <- tg[[1]]
# Get the number of intervals (vowel tokens)
num_intervals <- length(vowels_tier$t1)
# Loop through each interval (token)
for (i in seq_len(num_intervals)) {
# Trim extra white space from label and skip if empty
token_label <- trimws(vowels_tier$label[i])
if (nchar(token_label) == 0) next
# Retrieve start and end time for this token
start_time <- vowels_tier$t1[i]
end_time <- vowels_tier$t2[i]
# Extract the audio segment corresponding to this vowel token
segment <- extractWave(wave_obj, from = start_time, to = end_time, xunit = "time")
# Calculate MFCC's with 14 coefficients per frame
mfcc_features <- tryCatch({
melfcc(segment, sr = wave_obj@samp.rate, numcep = 14)
}, warning = function(w) {
invokeRestart("muffleWarning")
}, error = function(e) {
return(NULL)
})
if (is.null(mfcc_features)) next
# Save token info and its MFCC matrix into the list
mfcc_results[[length(mfcc_results) + 1]] <- list(
file   = basename(wav_path),
label  = token_label,
start  = start_time,
end    = end_time,
mfcc   = mfcc_features
)
}
}
# Convert mfcc_results to a tibble
df_mfcc <- tibble(
file  = sapply(mfcc_results, function(x) x$file),
label = sapply(mfcc_results, function(x) x$label),
start = sapply(mfcc_results, function(x) x$start),
end   = sapply(mfcc_results, function(x) x$end),
mfcc  = lapply(mfcc_results, function(x) x$mfcc)
)
### Summarize MFCCs by taking the mean of each coefficient across all frames:
df_mfcc <- df_mfcc %>%
mutate(mean_mfcc = map(mfcc, function(mat) {
if (is.matrix(mat)) {
avg <- apply(mat, 1, mean)
# Ensure the vector has exactly 14 values (pad with NA or truncate if needed)
if (length(avg) < 14) {
avg <- c(avg, rep(NA, 14 - length(avg)))
} else if (length(avg) > 14) {
avg <- avg[1:14]
}
avg
} else {
mat
}
}))
# Unnest the mean_mfcc list-column into 14 separate columns and rename them
df_mfcc <- df_mfcc %>%
unnest_wider(mean_mfcc, names_sep = "_")
colnames(df_mfcc)[grepl("^mean_mfcc_", colnames(df_mfcc))] <- paste0("MFCC_", 1:14)
# Clean up df_mfcc: filter unwanted tokens and assign vowel and emphasis categories
df_mfcc <- df_mfcc %>%
filter(!str_starts(label, "xx")) %>%
mutate(vowel = case_when(
str_starts(label, "ah") ~ "ɑ",
str_starts(label, "a") & !str_starts(label, "ah") ~ "æ",
str_starts(label, "i") ~ "i",
str_starts(label, "e") & !str_starts(label, "ex") ~ "ɛ",
str_starts(label, "ex") ~ "ə",
str_starts(label, "o") ~ "ø",
str_starts(label, "u") ~ "y",
TRUE ~ NA_character_
)) %>%
mutate(emphasis = case_when(
grepl("22", label) ~ "emphatic",
grepl("13$", label) ~ "mixed",
grepl("33", label) ~ "mixed",
TRUE ~ "plain"
)) %>%
mutate(syllable_status = case_when(
grepl("13$", label) ~ "plain_mixed",
grepl("33$", label) ~ "mixed",
grepl("22$", label) ~ "emphatic",
grepl("11$", label) ~ "plain",
TRUE ~ NA_character_
)) %>%
filter(!grepl("j", vowel)) %>%
filter(vowel != "ə")
### PART 2: XGBOOST MODELING USING ONLY MFCC FEATURES
# Prepare a final data frame for modeling using only MFCC features
df_final_mfcc <- df_mfcc %>%
filter(emphasis %in% c("plain", "emphatic")) %>%
select(vowel, emphasis, starts_with("MFCC_"))
set.seed(123)
results_mfcc <- list()
for (v in unique(df_final_mfcc$vowel)) {
df_subset <- df_final_mfcc %>% filter(vowel == v)
if (nrow(df_subset) < 10) next
X <- df_subset %>%
select(starts_with("MFCC_")) %>%
mutate(across(everything(), as.numeric)) %>%
as.matrix()
y <- as.numeric(ifelse(df_subset$emphasis == "emphatic", 1, 0))
dtrain <- xgb.DMatrix(data = X, label = y)
params <- list(
objective = "binary:logistic",
eval_metric = "error",
max_depth = 3,
eta = 0.1,
verbosity = 0
)
cv <- xgb.cv(
params = params,
data = dtrain,
nrounds = 50,
nfold = 5,
verbose = 0,
early_stopping_rounds = 10,
maximize = FALSE
)
best_error <- min(cv$evaluation_log$test_error_mean)
best_accuracy <- 1 - best_error
results_mfcc[[v]] <- list(
vowel = v,
n_tokens = nrow(df_subset),
best_error = best_error,
best_accuracy = best_accuracy
)
}
results_mfcc_df <- bind_rows(results_mfcc)
print("Results for MFCC-only model (using mean MFCCs with 14 coefficients):")
print(results_mfcc_df)
# Load required packages
library(tuneR)      # For audio file reading and processing
library(rPraat)     # For reading Praat TextGrid files
library(tidyverse)  # For data manipulation
library(xgboost)    # For modeling with XGBoost
library(caret)      # Optional, for additional modeling utilities
### PART 1: MFCC EXTRACTION & PROCESSING
data_dir <- "/Users/noahkhaloo/Desktop/Urmi_fieldwork/s1/vowels/vowels_arpabet"
wav_files <- list.files(path = data_dir, pattern = "\\.wav$", full.names = TRUE)
# Initialize empty list to store MFCC results
mfcc_results <- list()
# Loop through each audio file
for (wav_path in wav_files) {
# Get base name and corresponding TextGrid path
base_name <- tools::file_path_sans_ext(basename(wav_path))
tg_path <- file.path(data_dir, paste0(base_name, ".TextGrid"))
if (!file.exists(tg_path)) next
# Read audio file and TextGrid
wave_obj <- readWave(wav_path)
tg <- tg.read(tg_path)
# Assume the first tier is the vowels tier
vowels_tier <- tg[[1]]
# Get the number of intervals (vowel tokens)
num_intervals <- length(vowels_tier$t1)
# Loop through each interval (token)
for (i in seq_len(num_intervals)) {
# Trim extra white space from label and skip if empty
token_label <- trimws(vowels_tier$label[i])
if (nchar(token_label) == 0) next
# Retrieve start and end time for this token
start_time <- vowels_tier$t1[i]
end_time <- vowels_tier$t2[i]
# Extract the audio segment corresponding to this vowel token
segment <- extractWave(wave_obj, from = start_time, to = end_time, xunit = "time")
# Calculate MFCC's with 14 coefficients per frame
mfcc_features <- tryCatch({
melfcc(segment, sr = wave_obj@samp.rate, numcep = 14)
}, warning = function(w) {
invokeRestart("muffleWarning")
}, error = function(e) {
return(NULL)
})
if (is.null(mfcc_features)) next
# Save token info and its MFCC matrix into the list
mfcc_results[[length(mfcc_results) + 1]] <- list(
file   = basename(wav_path),
label  = token_label,
start  = start_time,
end    = end_time,
mfcc   = mfcc_features
)
}
}
# Convert mfcc_results to a tibble
df_mfcc <- tibble(
file  = sapply(mfcc_results, function(x) x$file),
label = sapply(mfcc_results, function(x) x$label),
start = sapply(mfcc_results, function(x) x$start),
end   = sapply(mfcc_results, function(x) x$end),
mfcc  = lapply(mfcc_results, function(x) x$mfcc)
)
### Summarize MFCCs by taking the mean of each coefficient across all frames:
df_mfcc <- df_mfcc %>%
mutate(mean_mfcc = map(mfcc, function(mat) {
if (is.matrix(mat)) {
avg <- apply(mat, 1, mean)
# Ensure the vector has exactly 14 values (pad with NA or truncate if needed)
if (length(avg) < 14) {
avg <- c(avg, rep(NA, 14 - length(avg)))
} else if (length(avg) > 14) {
avg <- avg[1:14]
}
avg
} else {
mat
}
}))
# Unnest the mean_mfcc list-column into 14 separate columns and rename them
df_mfcc <- df_mfcc %>%
unnest_wider(mean_mfcc, names_sep = "_")
colnames(df_mfcc)[grepl("^mean_mfcc_", colnames(df_mfcc))] <- paste0("MFCC_", 1:14)
# Clean up df_mfcc: filter unwanted tokens and assign vowel and emphasis categories
df_mfcc <- df_mfcc %>%
filter(!str_starts(label, "xx")) %>%
mutate(vowel = case_when(
str_starts(label, "ah") ~ "ɑ",
str_starts(label, "a") & !str_starts(label, "ah") ~ "æ",
str_starts(label, "i") ~ "i",
str_starts(label, "e") & !str_starts(label, "ex") ~ "ɛ",
str_starts(label, "ex") ~ "ə",
str_starts(label, "o") ~ "ø",
str_starts(label, "u") ~ "y",
TRUE ~ NA_character_
)) %>%
mutate(emphasis = case_when(
grepl("22", label) ~ "emphatic",
grepl("13$", label) ~ "mixed",
grepl("33", label) ~ "mixed",
TRUE ~ "plain"
)) %>%
mutate(syllable_status = case_when(
grepl("13$", label) ~ "plain_mixed",
grepl("33$", label) ~ "mixed",
grepl("22$", label) ~ "emphatic",
grepl("11$", label) ~ "plain",
TRUE ~ NA_character_
)) %>%
filter(!grepl("j", vowel)) %>%
filter(vowel != "ə")
### PART 2: XGBOOST MODELING USING ONLY MFCC FEATURES
# Prepare a final data frame for modeling using only MFCC features
df_final_mfcc <- df_mfcc %>%
filter(emphasis %in% c("plain", "emphatic")) %>%
select(vowel, emphasis, starts_with("MFCC_"))
set.seed(123)
results_mfcc <- list()
for (v in unique(df_final_mfcc$vowel)) {
df_subset <- df_final_mfcc %>% filter(vowel == v)
if (nrow(df_subset) < 10) next
X <- df_subset %>%
select(starts_with("MFCC_")) %>%
mutate(across(everything(), as.numeric)) %>%
as.matrix()
y <- as.numeric(ifelse(df_subset$emphasis == "emphatic", 1, 0))
dtrain <- xgb.DMatrix(data = X, label = y)
params <- list(
objective = "binary:logistic",
eval_metric = "error",
max_depth = 3,
eta = 0.1,
verbosity = 0
)
cv <- xgb.cv(
params = params,
data = dtrain,
nrounds = 50,
nfold = 5,
verbose = 0,
early_stopping_rounds = 10,
maximize = FALSE
)
best_error <- min(cv$evaluation_log$test_error_mean)
best_accuracy <- 1 - best_error
results_mfcc[[v]] <- list(
vowel = v,
n_tokens = nrow(df_subset),
best_error = best_error,
best_accuracy = best_accuracy
)
}
results_mfcc_df <- bind_rows(results_mfcc)
print("Results for MFCC-only model (using mean MFCCs with 14 coefficients):")
print(results_mfcc_df)
library(tuneR)
library(rPraat)
library(tidyverse)
library(xgboost)
library(caret)
### PART 1: MFCC EXTRACTION & PROCESSING
data_dir <- "/Users/noahkhaloo/Desktop/Urmi_fieldwork/s1/vowels/vowels_arpabet"
wav_files <- list.files(path = data_dir, pattern = "\\.wav$", full.names = TRUE)
# Initialize empty list to store MFCC results
mfcc_results <- list()
# Loop through each audio file
for (wav_path in wav_files) {
base_name <- tools::file_path_sans_ext(basename(wav_path))
tg_path <- file.path(data_dir, paste0(base_name, ".TextGrid"))
if (!file.exists(tg_path)) next
wave_obj <- readWave(wav_path)
tg <- tg.read(tg_path)
vowels_tier <- tg[[1]]  # assuming the first tier is vowels
num_intervals <- length(vowels_tier$t1)
for (i in seq_len(num_intervals)) {
token_label <- trimws(vowels_tier$label[i])
if (nchar(token_label) == 0) next
start_time <- vowels_tier$t1[i]
end_time <- vowels_tier$t2[i]
segment <- extractWave(wave_obj, from = start_time, to = end_time, xunit = "time")
mfcc_features <- tryCatch({
melfcc(segment, sr = wave_obj@samp.rate, numcep = 14)
}, warning = function(w) {
invokeRestart("muffleWarning")
}, error = function(e) {
return(NULL)
})
if (is.null(mfcc_features)) next
mfcc_results[[length(mfcc_results) + 1]] <- list(
file   = basename(wav_path),
label  = token_label,
start  = start_time,
end    = end_time,
mfcc   = mfcc_features
)
}
}
df_mfcc <- tibble(
file  = sapply(mfcc_results, function(x) x$file),
label = sapply(mfcc_results, function(x) x$label),
start = sapply(mfcc_results, function(x) x$start),
end   = sapply(mfcc_results, function(x) x$end),
mfcc  = lapply(mfcc_results, function(x) x$mfcc)
)
### Instead of averaging across all frames, extract the MFCC at the midpoint:
df_mfcc <- df_mfcc %>%
mutate(midpoint_mfcc = map(mfcc, function(mat) {
if (is.matrix(mat)) {
mid_index <- ceiling(ncol(mat) / 2)
mfcc_mid <- mat[, mid_index]  # extract the MFCC vector at the midpoint
# Ensure it's exactly 14-dimensional (pad/truncate if necessary)
if (length(mfcc_mid) < 14) {
mfcc_mid <- c(mfcc_mid, rep(NA, 14 - length(mfcc_mid)))
} else if (length(mfcc_mid) > 14) {
mfcc_mid <- mfcc_mid[1:14]
}
mfcc_mid
} else {
mat
}
}))
# Unnest the midpoint_mfcc list column into 14 separate numeric columns
df_mfcc <- df_mfcc %>%
unnest_wider(midpoint_mfcc, names_sep = "_")
colnames(df_mfcc)[grepl("^midpoint_mfcc_", colnames(df_mfcc))] <- paste0("MFCC_", 1:14)
# Process labels: assign vowel, emphasis, etc.
df_mfcc <- df_mfcc %>%
filter(!str_starts(label, "xx")) %>%
mutate(vowel = case_when(
str_starts(label, "ah") ~ "ɑ",
str_starts(label, "a") & !str_starts(label, "ah") ~ "æ",
str_starts(label, "i") ~ "i",
str_starts(label, "e") & !str_starts(label, "ex") ~ "ɛ",
str_starts(label, "ex") ~ "ə",
str_starts(label, "o") ~ "ø",
str_starts(label, "u") ~ "y",
TRUE ~ NA_character_
)) %>%
mutate(emphasis = case_when(
grepl("22", label) ~ "emphatic",
grepl("13$", label) ~ "mixed",
grepl("33", label) ~ "mixed",
TRUE ~ "plain"
)) %>%
mutate(syllable_status = case_when(
grepl("13$", label) ~ "plain_mixed",
grepl("33$", label) ~ "mixed",
grepl("22$", label) ~ "emphatic",
grepl("11$", label) ~ "plain",
TRUE ~ NA_character_
)) %>%
filter(!grepl("j", vowel)) %>%
filter(vowel != "ə")
### PART 2: (Optional) FORMANT DATA PROCESSING
# If you need formant info for later, process as before.
formants_s1_raw <- read_csv("/Users/noahkhaloo/Desktop/Urmi_fieldwork/s1/vowels/results_praat.csv")
process_vowels <- function(df) {
if ("Segment" %in% colnames(df)) {
df <- df %>%
mutate(Filename = sub("-.*", "", Filename)) %>%
filter(!str_starts(Segment, "xx")) %>%
mutate(vowel = case_when(
str_starts(Segment, "ah") ~ "ɑ",
str_starts(Segment, "a") & !str_starts(Segment, "ah") ~ "æ",
str_starts(Segment, "i") ~ "i",
str_starts(Segment, "e") & !str_starts(Segment, "ex") ~ "ɛ",
str_starts(Segment, "ex") ~ "ə",
str_starts(Segment, "o") ~ "ø",
str_starts(Segment, "u") ~ "y",
TRUE ~ NA_character_
)) %>%
mutate(emphasis = case_when(
grepl("22", Segment) ~ "emphatic",
grepl("13$", Segment) ~ "mixed",
grepl("33", Segment) ~ "mixed",
TRUE ~ "plain"
)) %>%
mutate(syllable_status = case_when(
grepl("13$", Segment) ~ "plain_mixed",
grepl("33$", Segment) ~ "mixed",
grepl("22$", Segment) ~ "emphatic",
grepl("11$", Segment) ~ "plain",
TRUE ~ NA_character_
)) %>%
filter(!grepl("j", vowel)) %>%
filter(vowel != "ə")
return(df)
} else {
stop("The dataframe does not have a 'Segment' column.")
}
}
formants_s1 <- process_vowels(formants_s1_raw)
# Create a combined data frame (if needed)
combined_df <- left_join(formants_s1, df_mfcc, by = "vowel")
# Now combined_df contains both formant info and MFCC features
### PART 3: XGBOOST MODELING USING ONLY MFCC FEATURES
# For the MFCC-only model, use df_mfcc directly.
df_final_mfcc <- df_mfcc %>%
filter(emphasis %in% c("plain", "emphatic")) %>%
select(vowel, emphasis, starts_with("MFCC_"))
set.seed(123)
results_mfcc <- list()
for (v in unique(df_final_mfcc$vowel)) {
df_subset <- df_final_mfcc %>% filter(vowel == v)
if (nrow(df_subset) < 10) next
X <- df_subset %>%
select(starts_with("MFCC_")) %>%
mutate(across(everything(), as.numeric)) %>%
as.matrix()
y <- as.numeric(ifelse(df_subset$emphasis == "emphatic", 1, 0))
dtrain <- xgb.DMatrix(data = X, label = y)
params <- list(
objective = "binary:logistic",
eval_metric = "error",
max_depth = 3,
eta = 0.1,
verbosity = 0
)
cv <- xgb.cv(
params = params,
data = dtrain,
nrounds = 50,
nfold = 5,
verbose = 0,
early_stopping_rounds = 10,
maximize = FALSE
)
best_error <- min(cv$evaluation_log$test_error_mean)
best_accuracy <- 1 - best_error
results_mfcc[[v]] <- list(
vowel = v,
n_tokens = nrow(df_subset),
best_error = best_error,
best_accuracy = best_accuracy
)
}
results_mfcc_df <- bind_rows(results_mfcc)
print("Results for MFCC-only model (using midpoint MFCCs):")
print(results_mfcc_df)
