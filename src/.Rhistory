#load csv
raw_data <- read.csv("/Users/ritalavi/Desktop/Urmi_fieldwork/data/fricatives/fricative_results.csv", header = FALSE)
vowels_total <- read_delim(
"/Users/ritalavi/Desktop/Urmi_fieldwork/s1/vowels/VS_s1.csv",
delim = "\t",
show_col_types = FALSE
)
library(tidyverse)
library(tidyverse)
#import csv
vowels_total <- read_delim(
"/Users/ritalavi/Desktop/Urmi_fieldwork/s1/vowels/VS_s1.csv",
delim = "\t",
show_col_types = FALSE
)
#select columns that we need
vowels <- vowels_total%>%
select(Filename, Label, seg_Start, seg_End, sF1, sF2, sF3)
#create duration column
vowels <- vowels %>%
mutate(duration = seg_End - seg_Start)
#filter out na's
vowels <- vowels %>%
filter(!is.na(sF1) & !is.na(sF2) & !is.na(sF3))
#remove any non-numeric values
vowels$sF1 <- as.numeric(gsub("[^0-9.-]", "", vowels$sF1))
vowels$sF2 <- as.numeric(gsub("[^0-9.-]", "", vowels$sF2))
vowels$sF3 <- as.numeric(gsub("[^0-9.-]", "", vowels$sF3))
#get mean value for formants
vowel_means <- vowels %>%
group_by(duration) %>%
summarise(
mean_sF1 = mean(sF1, na.rm = TRUE),
mean_sF2 = mean(sF2, na.rm = TRUE),
mean_sF3 = mean(sF3, na.rm = TRUE)
)
# Join the calculated means back to the original dataset based on 'duration'
vowels <- vowels %>%
left_join(vowel_means, by = "duration") %>%
distinct(duration, .keep_all = TRUE)  # Keep only one row per 'duration'
#re-select
vowels <- vowels %>%
select(Filename, Label, duration, mean_sF1, mean_sF2, mean_sF3)
#create new vowel column
vowels <- vowels %>%
mutate(vowel = substr(Label, 1, 1))
vowels <- vowels %>%
filter(!str_starts(Label, "xx")) %>%  # Filter out rows where Label starts with "xx"
mutate(vowel = case_when(
str_starts(Label, "ah") ~ "ɑ",   # If label starts with "ah", assign "ɑ"
str_starts(Label, "a") & !str_starts(Label, "ah") ~ "æ",  # If label starts with "a" but not "ah", assign "æ"
str_starts(Label, "i") ~ "i",
str_starts(Label, "e") ~ "ɛ",
str_starts(Label, "o") ~ "ø",
str_starts(Label, "u") ~ "y",
str_starts(Label, "ex") ~ "ə",
TRUE ~ NA_character_  # This ensures that if no condition is met, 'vowel' will be NA
))
#create emphasis column
vowels <- vowels %>%
mutate(emphasis = case_when(
grepl("22", Label) ~ "emphatic",
grepl("13$", Label) ~ "mixed",
grepl("33", Label) ~ "mixed",
TRUE ~ "plain"
))
#add syllable status column
vowels <- vowels %>%
mutate(syllable_status = case_when(
grepl("13$", Label) ~ "plain_mixed",
grepl("33$", Label) ~ "mixed",
grepl("22$", Label) ~ "emphatic",
grepl("11$", Label) ~ "plain",
TRUE ~ NA_character_  # For cases that don't match any condition
))
#rename
vowels <- vowels %>%
rename(
F1 = mean_sF1,
F2 = mean_sF2,
F3 = mean_sF3)
#filter out NA
vowels <- vowels %>%
filter(!is.na(vowel))
#calculate malanobis distance for formants
vmahalanobis = function (dat) {
if (nrow(dat) < 25) {
dat$zF1F2 = NA
return(dat)
}
means = c(mean(dat$F1, na.rm=T), mean(dat$F2, na.rm=T))
cov = cov(cbind(dat$F1, dat$F2))
dat$zF1F2 = mahalanobis(cbind(dat$F1, dat$F2),
center=means, cov=cov)
dat
}
# Distance larger than 6 is considered as outlier    #MG: smaller numbers = more outliers.
distance_cutoff = 6
# Perform Mahalanobis on dataset
vowels_filtered =  vowels %>%
group_by(vowel) %>%
do(vmahalanobis(.)) %>%
ungroup() %>%
mutate(formant_outlier = NA)
# Visualize the formants with flagged values
vowels_filtered %>%
filter(is.na(formant_outlier)) %>%
ggplot(aes(x = F2, y = F1, color = zF1F2 > distance_cutoff)) +
geom_point(size = 0.6) +
facet_wrap(.~vowel)+
scale_y_reverse(limits = c(2000,0),position = "right") +
scale_x_reverse(limits = c(3500,0),position = "top")+
theme_bw()
vowels
###could be a nice plot if I get more data###
#ridge plot
ggplot(data = df.diamonds,
mapping = aes(x = price,
y = color)) +
ggridges::geom_density_ridges(scale = 1.5)
final_plot
library(tidyverse)
library(lme4)
library(emmeans)
library(patchwork)
library(cowplot)
#load csv's
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv")
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data[1, ]))
#load csv's
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv")
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names)))
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names_s1)))
cleaned_data_s2 <- raw_data_s2 %>%
filter(!apply(., 1, function(row) all(row == column_names_s2)))
# Assign proper column names
colnames(cleaned_data_s1) <- column_names_s1
colnames(cleaned_data_s2) <- column_names_s2
colnames(cleaned_data_s2) <- column_names_s2
#add s1 and s2 columns
df_s1 <- cleaned_data_s1 %>%
mutate(source = "s1")
df_s2 <- cleaned_data_s2 %>%
mutate(source = "s2")
df_s2
df_s1
cleaned_data_s2
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv")
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names_s1)))
cleaned_data_s2 <- raw_data_s2 %>%
filter(!apply(., 1, function(row) all(row == column_names_s2)))
# Assign proper column names
colnames(cleaned_data_s1) <- column_names_s1
colnames(cleaned_data_s2) <- column_names_s2
#add s1 and s2 columns
df_s1 <- cleaned_data_s1 %>%
mutate(source = "s1")
df_s1
column_names_s1
#load csv's
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s1
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s1
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[0, ]))
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[0, ]))
column_names_s1
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv")
# Use the first row as the actual column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names_s1)))
cleaned_data_s2 <- raw_data_s2 %>%
filter(!apply(., 1, function(row) all(row == column_names_s2)))
# Assign proper column names
colnames(cleaned_data_s1) <- column_names_s1
colnames(cleaned_data_s2) <- column_names_s2
raw_data_s1
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv", col_names = FALSE)
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv", col_names = FALSE)
# Extract the first row as column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Remove the first row and set proper column names
cleaned_data_s1 <- raw_data_s1[-1, ]
colnames(cleaned_data_s1) <- column_names_s1
cleaned_data_s2 <- raw_data_s2[-1, ]
colnames(cleaned_data_s2) <- column_names_s2
# Optionally, remove duplicate rows (if duplicates exist beyond column names)
cleaned_data_s1 <- distinct(cleaned_data_s1)
cleaned_data_s2 <- distinct(cleaned_data_s2)
#add s1 and s2 columns
df_s1 <- cleaned_data_s1 %>%
mutate(source = "s1")
df_s1
# Load the CSVs without automatically using the first row as column names
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv", col_names = FALSE)
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv", col_names = FALSE)
# Extract the first row as column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Remove the first row and set proper column names
cleaned_data_s1 <- raw_data_s1[-1, ]
colnames(cleaned_data_s1) <- column_names_s1
cleaned_data_s2 <- raw_data_s2[-1, ]
colnames(cleaned_data_s2) <- column_names_s2
# Optionally, remove duplicate rows (if duplicates exist beyond column names)
cleaned_data_s1 <- distinct(cleaned_data_s1)
cleaned_data_s2 <- distinct(cleaned_data_s2)
view(cleaned_data_s1)
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv", col_names = FALSE)
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv", col_names = FALSE)
# Extract the first row as column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
# Remove the first row and set proper column names
cleaned_data_s1 <- raw_data_s1[-1, ]
colnames(cleaned_data_s1) <- column_names_s1
cleaned_data_s2 <- raw_data_s2[-1, ]
colnames(cleaned_data_s2) <- column_names_s2
#remove duplicate rows
cleaned_data_s1 <- distinct(cleaned_data_s1)
cleaned_data_s2 <- distinct(cleaned_data_s2)
raw_data_s1
# Extract the first row as column names
column_names_s1 <- as.character(unlist(raw_data_s1[1, ]))
column_names_s1
column_names_s2 <- as.character(unlist(raw_data_s2[1, ]))
column_names_s2
# Remove the first row and set proper column names
cleaned_data_s1 <- raw_data_s1[-1, ]
cleaned_data_s1
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv")
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv")
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data_s1[1, ]))
column_names
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data_s1[-1, ]))
column_names
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data_s1[1, ]))
raw_data_s1
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv", col_names = FALSE)
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv", col_names = FALSE)
raw_data_s1
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data_s1[1, ]))
column_names
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names)))
cleaned_data_s1
cleaned_data_s2 <- raw_data_s2 %>%
filter(!apply(., 1, function(row) all(row == column_names)))
cleaned_data_s2
# Assign proper column names
colnames(cleaned_data_s1) <- column_names
cleaned_data_s1
colnames(cleaned_data_s2) <- column_names
cleaned_data_s2
#function for fixing up df's
process_fricative_data <- function(df) {
df <- df %>%
# Create fricative column
mutate(fricative = ifelse(substr(label, 1, 2) == "sh", "sh", substr(label, 1, 1))) %>%
mutate(fricative = ifelse(fricative == "sh", "ʃ", fricative)) %>%
# Create emphatic column
mutate(emphasis = case_when(
grepl("22", label) ~ "emphatic",
TRUE ~ "plain"
)) %>%
# Create vowel column
mutate(vowel = case_when(
grepl("(ex|ə)$", label) ~ "ə",
grepl("ah$", label) ~ "ɑ",
grepl("(a|æ)$", label) & !grepl("ah$", label) ~ "æ",
grepl("(o|ø)$", label) ~ "ø",
grepl("i$", label) ~ "i",
grepl("(u|ʉ)$", label) ~ "ʉ",
grepl("xx$", label) ~ "əx",  # Updated here
grepl("(e|ɛ)$", label) ~ "ɛ",
grepl("ɑ$", label) ~ "ɑ",
TRUE ~ NA_character_
)) %>%
# Select COG and necessary columns
select(fricative, vowel, source, cog, emphasis)
return(df)
}
df_s1 <- process_fricative_data(df_s1)
df_s2 <- process_fricative_data(df_s2)
df_s1
#load csv's
raw_data_s1 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s1/fricatives/results_s1.csv", col_names = FALSE)
raw_data_s2 <- read_csv("/Users/ritalavi/Desktop/Urmi_fieldwork/s2/fricatives/results_s2.csv", col_names = FALSE)
# Use the first row as the actual column names
column_names <- as.character(unlist(raw_data_s1[1, ]))
# Remove any rows that are duplicates of the column names
cleaned_data_s1 <- raw_data_s1 %>%
filter(!apply(., 1, function(row) all(row == column_names)))
cleaned_data_s2 <- raw_data_s2 %>%
filter(!apply(., 1, function(row) all(row == column_names)))
# Assign proper column names
colnames(cleaned_data_s1) <- column_names
colnames(cleaned_data_s2) <- column_names
cleaned_data_s1
